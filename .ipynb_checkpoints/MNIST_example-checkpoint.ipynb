{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import torch\n",
    "import timeit\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from adamW import AdamW\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "from Loss import noisy_label_loss\n",
    "from Utilis import segmentation_scores, CustomDataset_punet, calculate_cm\n",
    "from Utilis import evaluate_noisy_label_4, evaluate_noisy_label_5, evaluate_noisy_label_6\n",
    "# our proposed model:\n",
    "from Models import UNet_CMs\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= #\n",
    "# Hyper-parameters setting\n",
    "# ========================= #\n",
    "\n",
    "# hyper-parameters for model:\n",
    "input_dim = 3 # dimension of input\n",
    "width = 24 # width of the network\n",
    "depth = 3 # depth of the network, downsampling times is (depth-1)\n",
    "class_no = 2 # class number, 2 for binary\n",
    "\n",
    "# hyper-parameters for training:\n",
    "train_batchsize = 5 # batch size\n",
    "alpha = 0.001 # weight of the trace regularisation of learnt confusion matrices\n",
    "num_epochs = 40 # total epochs\n",
    "learning_rate = 1e-2 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x936 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ======================================= #\n",
    "# Prepare a few data examples from MNIST \n",
    "# ======================================= #\n",
    "\n",
    "# Change path for your own datasets here:\n",
    "data_path = './MNIST_examples'\n",
    "dataset_tag = 'mnist'\n",
    "label_mode = 'multi'\n",
    "\n",
    "# full path to train/validate/test:\n",
    "test_path = data_path + '/test' \n",
    "train_path = data_path + '/train'\n",
    "validate_path = data_path + '/validate'\n",
    "\n",
    "# prepare data sets using our customdataset\n",
    "train_dataset = CustomDataset_punet(dataset_location=train_path, dataset_tag=dataset_tag, noisylabel=label_mode, augmentation=True)\n",
    "validate_dataset = CustomDataset_punet(dataset_location=validate_path, dataset_tag=dataset_tag, noisylabel=label_mode, augmentation=False)\n",
    "test_dataset = CustomDataset_punet(dataset_location=test_path, dataset_tag=dataset_tag, noisylabel=label_mode, augmentation=False)\n",
    "\n",
    "# putting dataset into data loaders\n",
    "trainloader = data.DataLoader(train_dataset, batch_size=train_batchsize, shuffle=True, num_workers=2, drop_last=True)\n",
    "validateloader = data.DataLoader(validate_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "testloader = data.DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "# demonstrate the training samples:\n",
    "Image_index_to_demonstrate = 6\n",
    "images, labels_over, labels_under, labels_wrong, labels_good, imagename = validate_dataset[Image_index_to_demonstrate]\n",
    "images = np.mean(images, axis=0)\n",
    "# print('The dimension of image, channel:' + str(np.shape(images)[0]) + ', height:' + str(np.shape(images)[1]) + ', width:' + str(np.shape(images)[2]))\n",
    "# print('The dimension of label, channel:' + str(np.shape(labels_over)[0]) + ', height:' + str(np.shape(labels_over)[1]) + ', width:' + str(np.shape(labels_over)[2]))\n",
    "\n",
    "# plot input image:\n",
    "# the input image is original mnist images with gaussian noises\n",
    "# plt.imshow(np.mean(images, axis=0), cmap='gray')\n",
    "# plt.title('Input image')\n",
    "# plt.show()\n",
    "\n",
    "# plot the labels:\n",
    "fig = plt.figure(figsize=(9, 13))\n",
    "columns = 5\n",
    "rows = 1\n",
    "ax = []\n",
    "labels = []\n",
    "labels_names = []\n",
    "labels.append(images)\n",
    "labels.append(labels_over)\n",
    "labels.append(labels_under)\n",
    "labels.append(labels_wrong)\n",
    "labels.append(labels_good)\n",
    "labels_names.append('Input')\n",
    "labels_names.append('Over label')\n",
    "labels_names.append('Under label')\n",
    "labels_names.append('Wrong label')\n",
    "labels_names.append('Good label')\n",
    "\n",
    "for i in range(columns*rows):\n",
    "    if i != 0:\n",
    "        label_ = labels[i][0, :, :]\n",
    "    else:\n",
    "        label_ = labels[i]\n",
    "    ax.append(fig.add_subplot(rows, columns, i+1))\n",
    "    ax[-1].set_title(labels_names[i]) \n",
    "    plt.imshow(label_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet_CMs(\n",
       "  (decoders): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "    )\n",
       "  )\n",
       "  (encoders): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (5): PReLU(num_parameters=1)\n",
       "    )\n",
       "  )\n",
       "  (decoders_noisy_layers): ModuleList(\n",
       "    (0): cm_layers(\n",
       "      (conv_1): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv_2): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv_last): Conv2d(24, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (1): cm_layers(\n",
       "      (conv_1): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv_2): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv_last): Conv2d(24, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (2): cm_layers(\n",
       "      (conv_1): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv_2): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv_last): Conv2d(24, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (3): cm_layers(\n",
       "      (conv_1): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv_2): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv_last): Conv2d(24, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "  )\n",
       "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (conv_last): Conv2d(24, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== #\n",
    "# Model\n",
    "# ===== #\n",
    "\n",
    "# call model:\n",
    "model = UNet_CMs(in_ch=input_dim, width=width, depth=depth, class_no=class_no, norm='in', low_rank=False)\n",
    "\n",
    "# model name for saving:\n",
    "model_name = 'UNet_Confusion_Matrices_' + '_width' + str(width) + \\\n",
    "           '_depth' + str(depth) + '_train_batch_' + str(train_batchsize) + \\\n",
    "           '_alpha_' + str(alpha) + '_e' + str(num_epochs) + \\\n",
    "           '_lr' + str(learning_rate) \n",
    "\n",
    "# setting up device:\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================== #\n",
    "# Prepare folders to save trained models and results \n",
    "# =================================================== #\n",
    "\n",
    "# save location:\n",
    "saved_information_path = './Results'\n",
    "try:\n",
    "    os.mkdir(saved_information_path)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "saved_information_path = saved_information_path + '/' + model_name\n",
    "try:\n",
    "    os.mkdir(saved_information_path)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "saved_model_path = saved_information_path + '/trained_models'\n",
    "try:\n",
    "    os.mkdir(saved_model_path)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "save_path_visual_result = saved_information_path + '/visual_results'\n",
    "try:\n",
    "    os.mkdir(save_path_visual_result)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "# tensorboardX file saved location:\n",
    "writer = SummaryWriter('./Results/Log_' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alarroza/.local/lib/python3.6/site-packages/torch/autograd/__init__.py:127: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:924.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n",
      "/home/alarroza/Projects/LID_HEALTH/Learn_Noisy_Labels_Medical_Images/adamW.py:100: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_noisy_label_4() missing 1 required positional argument: 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ee2bb6ecbda6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m             v_dice, v_ged = evaluate_noisy_label_4(data=validateloader,\n\u001b[1;32m     62\u001b[0m                                                    \u001b[0mmodel1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                                                    class_no=class_no)\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             print(\n",
      "\u001b[0;31mTypeError\u001b[0m: evaluate_noisy_label_4() missing 1 required positional argument: 'device'"
     ]
    }
   ],
   "source": [
    "# =================================================== #\n",
    "# Training\n",
    "# =================================================== #\n",
    "\n",
    "# We use adamW optimiser for more accurate L2 regularisation\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_loss_ce = 0\n",
    "    running_loss_trace = 0\n",
    "    running_iou = 0\n",
    "    \n",
    "    for j, (images, labels_over, labels_under, labels_wrong, labels_good, imagename) in enumerate(trainloader):\n",
    "        \n",
    "        b, c, h, w = images.size()\n",
    "        \n",
    "        # zero graidents before each iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # cast numpy data into tensor float\n",
    "        images = images.to(device=device, dtype=torch.float32)\n",
    "        labels_over = labels_over.to(device=device, dtype=torch.float32)\n",
    "        labels_under = labels_under.to(device=device, dtype=torch.float32)\n",
    "        labels_wrong = labels_wrong.to(device=device, dtype=torch.float32)\n",
    "        labels_good = labels_good.to(device=device, dtype=torch.float32)\n",
    "        \n",
    "        labels_all = []\n",
    "        labels_all.append(labels_over)\n",
    "        labels_all.append(labels_under)\n",
    "        labels_all.append(labels_wrong)\n",
    "        labels_all.append(labels_good)\n",
    "        \n",
    "        # model has two outputs: \n",
    "        # first one is the probability map for true ground truth \n",
    "        # second one is a list collection of probability maps for different noisy ground truths\n",
    "        outputs_logits, outputs_logits_noisy = model(images)\n",
    "        \n",
    "        # calculate loss:\n",
    "        # loss: total loss\n",
    "        # loss_ce: main cross entropy loss\n",
    "        # loss_trace: regularisation loss\n",
    "        loss, loss_ce, loss_trace = noisy_label_loss(outputs_logits, outputs_logits_noisy, labels_all, alpha)\n",
    "\n",
    "        # calculate the gradients:\n",
    "        loss.backward()\n",
    "        # update weights in model:\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, train_output = torch.max(outputs_logits, dim=1)\n",
    "        train_iou = segmentation_scores(labels_good.cpu().detach().numpy(), train_output.cpu().detach().numpy(), class_no)\n",
    "        running_loss += loss\n",
    "        running_loss_ce += loss_ce\n",
    "        running_loss_trace += loss_trace\n",
    "        running_iou += train_iou\n",
    "\n",
    "        if (j + 1) == 1:\n",
    "            # check the validation accuray at the begning of each epoch:\n",
    "            v_dice, v_ged = evaluate_noisy_label_4(data=validateloader,\n",
    "                                                   model1=model,\n",
    "                                                   class_no=class_no,\n",
    "                                                  device=device)\n",
    "            \n",
    "            print(\n",
    "                'Step [{}/{}], '\n",
    "                'Val dice: {:.4f},'\n",
    "                'Val GED: {:.4f},'\n",
    "                'loss main: {:.4f},'\n",
    "                'loss regualrisation: {:.4f},'.format(epoch + 1, num_epochs,\n",
    "                                                            v_dice,\n",
    "                                                            v_ged,\n",
    "                                                            running_loss_ce / (j + 1),\n",
    "                                                            running_loss_trace / (j + 1)))\n",
    "        \n",
    "            writer.add_scalars('scalars', {'loss': running_loss / (j + 1),\n",
    "                                           'train iou': running_iou / (j + 1),\n",
    "                                           'val iou': v_dice,\n",
    "                                           'train main loss': running_loss_ce / (j + 1),\n",
    "                                           'train regularisation loss': running_loss_trace / (j + 1)}, epoch + 1)\n",
    "\n",
    "# save model:\n",
    "save_model_name_full = saved_model_path + '/' + model_name + '_Final.pt'\n",
    "torch.save(model, save_model_name_full)\n",
    "print('\\n')\n",
    "print('Training ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================== #\n",
    "# Testing\n",
    "# =================================================== #\n",
    "model.eval()\n",
    "for i, (v_images, labels_over, labels_under, labels_wrong, labels_good, imagename) in enumerate(testloader):\n",
    "        v_images = v_images.to(device=device, dtype=torch.float32)\n",
    "        v_outputs_logits_original, v_outputs_logits_noisy = model(v_images)\n",
    "        b, c, h, w = v_outputs_logits_original.size()\n",
    "        # plot the final segmentation map\n",
    "        v_outputs_logits_original = nn.Softmax(dim=1)(v_outputs_logits_original)\n",
    "        _, v_outputs_logits = torch.max(v_outputs_logits_original, dim=1)\n",
    "\n",
    "        save_name = save_path_visual_result + '/test_' + str(i) + '_seg.png'\n",
    "        save_name_label = save_path_visual_result + '/test_' + str(i) + '_label.png'\n",
    "        save_name_slice = save_path_visual_result + '/test_' + str(i) + '_img.png'\n",
    "\n",
    "        plt.imsave(save_name_slice, v_images[:, 1, :, :].reshape(h, w).cpu().detach().numpy(), cmap='gray')\n",
    "        plt.imsave(save_name, v_outputs_logits.reshape(h, w).cpu().detach().numpy(), cmap='gray')\n",
    "        plt.imsave(save_name_label, labels_good.reshape(h, w).cpu().detach().numpy(), cmap='gray')\n",
    "        \n",
    "        # plot the noisy segmentation maps:\n",
    "        v_outputs_logits_original = v_outputs_logits_original.reshape(b, c, h*w)\n",
    "        v_outputs_logits_original = v_outputs_logits_original.permute(0, 2, 1).contiguous()\n",
    "        v_outputs_logits_original = v_outputs_logits_original.view(b * h * w, c).view(b*h*w, c, 1)\n",
    "        for j, cm in enumerate(v_outputs_logits_noisy):\n",
    "            cm = cm.view(b, c**2, h*w).permute(0, 2, 1).contiguous().view(b*h*w, c*c).view(b*h*w, c, c)\n",
    "            cm = cm / cm.sum(1, keepdim=True)\n",
    "            v_noisy_output_original = torch.bmm(cm, v_outputs_logits_original).view(b*h*w, c)\n",
    "            v_noisy_output_original = v_noisy_output_original.view(b, h*w, c).permute(0, 2, 1).contiguous().view(b, c, h, w)\n",
    "            _, v_noisy_output = torch.max(v_noisy_output_original, dim=1)\n",
    "            save_name = save_path_visual_result + '/test_' + str(i) + '_noisy_' + str(j) + '_seg.png'\n",
    "            plt.imsave(save_name, v_noisy_output.reshape(h, w).cpu().detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 482.4x936 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x936 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================================== #\n",
    "# Predictions Plot\n",
    "# =================================================== #\n",
    "test_data_index = 15\n",
    "\n",
    "over_seg = save_path_visual_result + '/test_' + str(test_data_index) + '_noisy_' + str(0) + '_seg.png'\n",
    "under_seg = save_path_visual_result + '/test_' + str(test_data_index) + '_noisy_' + str(1) + '_seg.png'\n",
    "wrong_seg = save_path_visual_result + '/test_' + str(test_data_index) + '_noisy_' + str(2) + '_seg.png'\n",
    "good_seg = save_path_visual_result + '/test_' + str(test_data_index) + '_noisy_' + str(3) + '_seg.png'\n",
    "\n",
    "seg = save_path_visual_result + '/test_' + str(test_data_index) + '_seg.png'\n",
    "label = save_path_visual_result + '/test_' + str(test_data_index) + '_label.png'\n",
    "img = save_path_visual_result + '/test_' + str(test_data_index) + '_img.png'\n",
    "\n",
    "# plot image, ground truth and final segmentation\n",
    "fig = plt.figure(figsize=(6.7, 13))\n",
    "columns = 3\n",
    "rows = 1\n",
    "\n",
    "ax = []\n",
    "imgs = []\n",
    "imgs_names = []\n",
    "\n",
    "imgs.append(img)\n",
    "imgs.append(label)\n",
    "imgs.append(seg)\n",
    "\n",
    "imgs_names.append('Test img')\n",
    "imgs_names.append('GroundTruth')\n",
    "imgs_names.append('Pred of true seg')\n",
    "\n",
    "for i in range(columns*rows):\n",
    "    img_ = imgs[i]\n",
    "    ax.append(fig.add_subplot(rows, columns, i+1))\n",
    "    ax[-1].set_title(imgs_names[i]) \n",
    "    img_ = Image.open(img_)\n",
    "    img_ = np.array(img_, dtype='uint8')\n",
    "    plt.imshow(img_, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# plot the segmentation for noisy labels:\n",
    "fig = plt.figure(figsize=(9, 13))\n",
    "columns = 4\n",
    "rows = 1\n",
    "\n",
    "ax = []\n",
    "noisy_segs = []\n",
    "noisy_segs_names = []\n",
    "\n",
    "noisy_segs.append(over_seg)\n",
    "noisy_segs.append(under_seg)\n",
    "noisy_segs.append(wrong_seg)\n",
    "noisy_segs.append(good_seg)\n",
    "\n",
    "noisy_segs_names.append('Pred of over')\n",
    "noisy_segs_names.append('Pred of under')\n",
    "noisy_segs_names.append('Pred of wrong')\n",
    "noisy_segs_names.append('Pred of good')\n",
    "\n",
    "for i in range(columns*rows):\n",
    "    noisy_seg_ = noisy_segs[i]\n",
    "    ax.append(fig.add_subplot(rows, columns, i+1))\n",
    "    ax[-1].set_title(noisy_segs_names[i]) \n",
    "    noisy_seg_ = Image.open(noisy_seg_)\n",
    "    noisy_seg_ = np.array(noisy_seg_, dtype='uint8' )\n",
    "    plt.imshow(noisy_seg_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
